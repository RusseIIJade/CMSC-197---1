{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8085ac8",
   "metadata": {},
   "source": [
    "# HW4 No Stop Words Version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a4439e",
   "metadata": {},
   "source": [
    "Submitted by Russel Jade Tumanon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca17a16",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6d3d150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sklearn\n",
    "import sklearn.metrics\n",
    "\n",
    "#For Preprocessing and results\n",
    "import email\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46e2c2b",
   "metadata": {},
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7b8b51",
   "metadata": {},
   "source": [
    "## Creating Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3df4053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>data/000/000</td>\n",
       "      <td>Received: from rodan.UU.NET by aramis.rutgers....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>data/000/001</td>\n",
       "      <td>Received: from unknown (HELO groucho.cs.psu.ed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>data/000/002</td>\n",
       "      <td>Received:\\n\\tfrom 24-151-178-89.dhcp.kgpt.tn.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>data/000/003</td>\n",
       "      <td>Received: from psuvax1.cs.psu.edu ([130.203.2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>data/000/004</td>\n",
       "      <td>Received: from 201-1-198-159.dsl.telesp.net.br...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label          path                                           contents\n",
       "0   ham  data/000/000  Received: from rodan.UU.NET by aramis.rutgers....\n",
       "1  spam  data/000/001  Received: from unknown (HELO groucho.cs.psu.ed...\n",
       "2  spam  data/000/002  Received:\\n\\tfrom 24-151-178-89.dhcp.kgpt.tn.c...\n",
       "3   ham  data/000/003  Received: from psuvax1.cs.psu.edu ([130.203.2....\n",
       "4  spam  data/000/004  Received: from 201-1-198-159.dsl.telesp.net.br..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating table or dataframe to easily view the parts\n",
    "labels_file = []\n",
    "labels = []\n",
    "path = []\n",
    "temp = []\n",
    "email_contents = []\n",
    "\n",
    "#Setting DataFrame\n",
    "emails = pd.DataFrame()\n",
    "\n",
    "#Open labels file\n",
    "with open('labels') as file:\n",
    "    labels_file = file.readlines()\n",
    "\n",
    "#Remove New lines   \n",
    "for i in labels_file:\n",
    "    temp.append(i.replace(\"\\n\", \"\"))\n",
    "    \n",
    "labels_file = temp\n",
    "\n",
    "#Get the label, addr/path, and email contents\n",
    "for i in labels_file:\n",
    "    label, separator, addr = i.partition(\" \")\n",
    "    addr = addr[3:]\n",
    "    path.append(addr)\n",
    "    labels.append(label)\n",
    "\n",
    "    #Put each email content to email_contents\n",
    "    with open(addr, \"r\", errors='ignore') as currFile:\n",
    "        contents = currFile.read()\n",
    "        email_contents.append(contents)\n",
    "        \n",
    "        currFile.close()\n",
    "\n",
    "#Assigning colum names \n",
    "emails[\"label\"] = labels\n",
    "emails[\"path\"] = path\n",
    "emails[\"contents\"] = email_contents\n",
    "\n",
    "#Print first 5 \n",
    "emails.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32911123",
   "metadata": {},
   "source": [
    "## Cleaning the Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0a9b49",
   "metadata": {},
   "source": [
    "### Functions to Format Email Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b85f6eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a function for string emails\n",
    "def email_messg(email_str):\n",
    "    message_str = email.message_from_string(email_str)\n",
    "    mssg = ''\n",
    "    \n",
    "    #Get Payload\n",
    "    try:\n",
    "        for payload in message_str.get_payload():\n",
    "            mssg = payload.get_payload()\n",
    "    except:\n",
    "        mssg = message_str.get_payload()\n",
    "\n",
    "    #Calls the multipart function if it's not a string\n",
    "    if(type(mssg) != str):\n",
    "        mssg = multipart(email_str)\n",
    "    return str(mssg)\n",
    "\n",
    "#Creating a function for multipart emails\n",
    "def multipart(email_content_str):\n",
    "    email_body = email.message_from_string(email_content_str)\n",
    "    content = \"\"\n",
    "    \n",
    "    #Get the body for multipart emails\n",
    "    if email_body.is_multipart():\n",
    "        \n",
    "        #Get the content type and disposition\n",
    "        for i in email_body.walk():\n",
    "            content_type = i.get_content_type()\n",
    "            content_dispo = str(i.get('Content-Disposition'))\n",
    "            \n",
    "            #Will skip if the content type is text/plain and content disposition do not contain attachment\n",
    "            if content_type == 'text/plain' and 'attachment' not in content_dispo:\n",
    "                \n",
    "                #Decode payload\n",
    "                content = i.get_payload(decode=True)\n",
    "                break\n",
    "                \n",
    "    #If not multipart\n",
    "    else:\n",
    "        \n",
    "        #Decode payload\n",
    "        content = email_body.get_payload(decode=True)\n",
    "    try:\n",
    "        \n",
    "         #Decode content\n",
    "        content = content.decode()\n",
    "    except:\n",
    "        try:\n",
    "            \n",
    "            #Decode content 'latin-1'\n",
    "            content = content.decode('latin-1')\n",
    "        except:\n",
    "            pass\n",
    "    return(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6b6a14",
   "metadata": {},
   "source": [
    "### Store all Formatted Email Contents to a List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3a5c623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted Result Sample:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The mailing list I queried about a few weeks ago is now up and\\nrunning.  I have also set up an archive server; see below.  The\\nfollowing is the official welcome to the list message at the moment.\\n\\nJoe Buehler\\n\\n--------------------\\n\\nThis mailing list is for people who desire serious, orthodox\\ndiscussion of the Roman Catholic religion.  I assume that it will\\ncater mainly to Catholics, but everyone else is welcome, provided they\\noperate within the below guidelines.  My own interests have a\\ndoctrinal bent, but I\\'m certainly not going to limit this list to just\\nthat sort of discussion.\\n\\nHaving participated in USENET religion groups for about 5 years now,\\none of my primary observations about Catholics on the net is that they\\ndo not know their religion very well.  My hope is that this list might\\nhelp remedy this problem to some extent.  I would like to make this a\\nnet resource available for Catholics who want to know more about their\\nreligion.\\n\\nAs far as moderation policy goes: The Catholic Church is not a\\ndemocracy, it\\'s a monarchy subject to a divinely given constitution.\\nI don\\'t set the rules in the Church, neither does my parish priest,\\nnor does my bishop, nor does the Pope.  Everyone has to adhere to the\\nway Christ set things up.  I think it follows that it\\'s not really\\nappropriate for someone to call himself a Catholic and argue with this\\nstate of affairs.  If you want to be Catholic, it\\'s simple enough, you\\nhave to follow the teaching of the Church.\\n\\nThe moderation policy will reflect this way of thinking: there are\\nplenty of other places on the net where Catholic doctrine can be\\nfreely attacked!  If in doubt, you can always subscribe, and see\\nwhether the list is to your taste.\\n\\nBesides the mailing list, there are a few other things that may be of\\ninterest:\\n\\n- I have set up an archive server that we can put interesting things\\nin.  (It doesn\\'t have anything in it at the moment except some UNIX\\nsoftware useful for such endeavors.)  Sorry, guys, but nothing that\\'s\\ncopyrighted goes into it!\\n\\n- I am planning on setting up a quotation server that can email\\nperiodic interesting citations from the principal sources of Catholic\\ndoctrine.  (Not done yet.)\\n\\n- I have obtained permission from the English language publishers of\\nthe Italian Catholic magazine \"30 Days\" to take material from their\\nmagazine.  I intend to scan some of the more interesting pictures\\n(ever seen a Cristero?  or St. Pius X?) and put them in the archives,\\nand also post extracts from some of the more interesting articles.\\n(It\\'s a European magazine, and is of generally higher quality than\\nAmerican Catholic material.  In my opinion...)\\n\\nIf you have any questions, would like to subscribe, etc., send email\\nto\\n\\n\\tcatholic@sarto.budd-lake.nj.us\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Store all contents to email_contents\n",
    "email_contents = []\n",
    "for i in emails.contents:\n",
    "    email_contents.append(email_messg(i))\n",
    "\n",
    "#Sample\n",
    "print(f\"Formatted Result Sample:\")\n",
    "email_contents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c65efe",
   "metadata": {},
   "source": [
    "### NO Stop Words "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bec7599",
   "metadata": {},
   "source": [
    "### Functions to  Clean the Email Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8b78217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Result Sample:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the mailing list i queried about a few weeks ago is now up and running  i have also set up an archive server  see below  the following is the official welcome to the list message at the moment  joe buehler                      this mailing list is for people who desire serious  orthodox discussion of the roman catholic religion  i assume that it will cater mainly to catholics  but everyone else is welcome  provided they operate within the below guidelines  my own interests have a doctrinal bent  but i m certainly not going to limit this list to just that sort of discussion  having participated in usenet religion groups for about   years now  one of my primary observations about catholics on the net is that they do not know their religion very well  my hope is that this list might help remedy this problem to some extent  i would like to make this a net resource available for catholics who want to know more about their religion  as far as moderation policy goes  the catholic church is not a democracy  it s a monarchy subject to a divinely given constitution  i don t set the rules in the church  neither does my parish priest  nor does my bishop  nor does the pope  everyone has to adhere to the way christ set things up  i think it follows that it s not really appropriate for someone to call himself a catholic and argue with this state of affairs  if you want to be catholic  it s simple enough  you have to follow the teaching of the church  the moderation policy will reflect this way of thinking  there are plenty of other places on the net where catholic doctrine can be freely attacked  if in doubt  you can always subscribe  and see whether the list is to your taste  besides the mailing list  there are a few other things that may be of interest    i have set up an archive server that we can put interesting things in   it doesn t have anything in it at the moment except some unix software useful for such endeavors   sorry  guys  but nothing that s copyrighted goes into it    i am planning on setting up a quotation server that can email periodic interesting citations from the principal sources of catholic doctrine   not done yet     i have obtained permission from the english language publishers of the italian catholic magazine    days  to take material from their magazine  i intend to scan some of the more interesting pictures  ever seen a cristero  or st  pius x   and put them in the archives  and also post extracts from some of the more interesting articles   it s a european magazine  and is of generally higher quality than american catholic material  in my opinion     if you have any questions  would like to subscribe  etc   send email to catholic sarto budd lake nj us'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a function to clean email contents\n",
    "#Stop Words not included\n",
    "def clean(email_content_str):\n",
    "\n",
    "    #Lower case all words\n",
    "    email_content_str = email_content_str.lower().split()\n",
    "    #Joining to string\n",
    "    email_content_str = ' '.join(email_content_str)   \n",
    "    \n",
    "    #Removing non-alphanumeric characters\n",
    "    email_content_str = re.sub(r'[^a-zA-Z0-9]', ' ', email_content_str)\n",
    "\n",
    "    #Removing numbers\n",
    "    email_content_str = re.sub('\\d+', ' ', email_content_str)\n",
    "    \n",
    "    #Removing website links\n",
    "    email_content_str = re.sub(r'\\bhttp\\S*\\b', ' ', email_content_str)\n",
    "    email_content_str = re.sub(r'\\bwww\\S*', ' ', email_content_str)\n",
    "    \n",
    "    #Return cleaned email\n",
    "    return(email_content_str)\n",
    "\n",
    "#Creating a function to clean evey email content\n",
    "def clean_emails(email_contents):\n",
    "    cleaned_emails = []\n",
    "    for email_content_str in email_contents:\n",
    "        cleaned_emails.append(clean(email_content_str))\n",
    "    \n",
    "    return cleaned_emails\n",
    "\n",
    "cleaned_emails = clean_emails(email_contents)\n",
    "\n",
    "#Sample\n",
    "print(f\"Cleaned Result Sample:\")\n",
    "cleaned_emails[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eba549",
   "metadata": {},
   "source": [
    "### Update DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3199a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "      <th>contents</th>\n",
       "      <th>cleaned_contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>data/000/000</td>\n",
       "      <td>Received: from rodan.UU.NET by aramis.rutgers....</td>\n",
       "      <td>the mailing list i queried about a few weeks a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>data/000/001</td>\n",
       "      <td>Received: from unknown (HELO groucho.cs.psu.ed...</td>\n",
       "      <td>luxury watches   buy your own rolex for only  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>data/000/002</td>\n",
       "      <td>Received:\\n\\tfrom 24-151-178-89.dhcp.kgpt.tn.c...</td>\n",
       "      <td>academic qualifications available from prestig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>data/000/003</td>\n",
       "      <td>Received: from psuvax1.cs.psu.edu ([130.203.2....</td>\n",
       "      <td>greetings all  this is to verify your subscrip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>data/000/004</td>\n",
       "      <td>Received: from 201-1-198-159.dsl.telesp.net.br...</td>\n",
       "      <td>html   head   meta   equiv  content language ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label          path                                           contents  \\\n",
       "0   ham  data/000/000  Received: from rodan.UU.NET by aramis.rutgers....   \n",
       "1  spam  data/000/001  Received: from unknown (HELO groucho.cs.psu.ed...   \n",
       "2  spam  data/000/002  Received:\\n\\tfrom 24-151-178-89.dhcp.kgpt.tn.c...   \n",
       "3   ham  data/000/003  Received: from psuvax1.cs.psu.edu ([130.203.2....   \n",
       "4  spam  data/000/004  Received: from 201-1-198-159.dsl.telesp.net.br...   \n",
       "\n",
       "                                    cleaned_contents  \n",
       "0  the mailing list i queried about a few weeks a...  \n",
       "1  luxury watches   buy your own rolex for only  ...  \n",
       "2  academic qualifications available from prestig...  \n",
       "3  greetings all  this is to verify your subscrip...  \n",
       "4   html   head   meta   equiv  content language ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Update dataframe contents\n",
    "emails[\"cleaned_contents\"] = cleaned_emails\n",
    "emails.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23d2d29",
   "metadata": {},
   "source": [
    "## Splitting the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ffe74f",
   "metadata": {},
   "source": [
    "### Train Set for Ham and Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fffacbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Train remember that it has 21,300 emails so we count index 0 to 21300\n",
    "email_train = emails[0:21300]\n",
    "\n",
    "#For ham training set \n",
    "email_train_ham = email_train[email_train['label'].str.contains('ham')]\n",
    "#For spam training set \n",
    "email_train_spam = email_train[email_train['label'].str.contains('spam')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5d24c2",
   "metadata": {},
   "source": [
    "### Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44385537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Test remember that it has 16,522 emails so we count from train's last index to the total emails + 1 = 37823\n",
    "email_test = emails[21300:37823]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36e2f5f",
   "metadata": {},
   "source": [
    "### Checking Emails of Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f44f0e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (21300, 4)\n",
      "Trainset shape for ham: (7523, 4)\n",
      "Train set shape for spam: (13777, 4)\n",
      "\n",
      "Splitting Train dataset for ham and spam successful!\n",
      "\n",
      "Test set shape: (16522, 4)\n"
     ]
    }
   ],
   "source": [
    "#Check Train Set\n",
    "print(\"Train set shape:\", email_train.shape)\n",
    "print(\"Trainset shape for ham:\", email_train_ham.shape)\n",
    "print(\"Train set shape for spam:\", email_train_spam.shape)\n",
    "\n",
    "#Checks if the number of emails from the training dataset of ham and spam is equal to the total train emails (21300)\n",
    "if (email_train_ham.shape[0] + email_train_spam.shape[0] == 21300):\n",
    "    print(\"\\nSplitting Train dataset for ham and spam successful!\")\n",
    "else:\n",
    "    print(\"Emails do not add up!\")\n",
    "\n",
    "#Check Test Set \n",
    "print(\"\\nTest set shape:\", email_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c580999",
   "metadata": {},
   "source": [
    "## Occurrence of Unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0629e1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>occurence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d</td>\n",
       "      <td>242061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>241090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>228292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>197327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>div</td>\n",
       "      <td>157355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>shin</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>flip</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>marshall</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>objectives</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>concur</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  occurence\n",
       "0              d     242061\n",
       "1              b     241090\n",
       "2              e     228292\n",
       "3              a     197327\n",
       "4            div     157355\n",
       "...          ...        ...\n",
       "9995        shin         31\n",
       "9996        flip         31\n",
       "9997    marshall         31\n",
       "9998  objectives         31\n",
       "9999      concur         31\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Counting the occurrence of each unique word in cleaned_contents using a Counter\n",
    "unique = Counter(\" \".join(email_train['cleaned_contents']).split()).most_common(10000)\n",
    "dictionary = pd.DataFrame(unique, columns = ['word', 'occurence'])\n",
    "\n",
    "dictionary.head(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffce4c48",
   "metadata": {},
   "source": [
    "# 2. Creating the feature matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb62eac",
   "metadata": {},
   "source": [
    "### For Ham Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "731ba4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents_list_ham = email_train_ham['cleaned_contents'].tolist()\n",
    "dict_words = dictionary['word'].tolist()\n",
    "\n",
    "#Create empty feature matrix\n",
    "feature_matrix_ham = np.zeros((len(contents_list_ham), len(dict_words)))\n",
    "\n",
    "#Loop over the emails\n",
    "for i, email in enumerate(contents_list_ham):\n",
    "    \n",
    "    #Check if the word in the dictionary appears in the email\n",
    "    for j, word in enumerate(dict_words):\n",
    "        if word in email:\n",
    "            #If it appears, set the value to 1\n",
    "            feature_matrix_ham[i, j] = 1\n",
    "    else:\n",
    "        #Set to 0\n",
    "        feature_matrix_ham[i, j] = 0\n",
    "\n",
    "feature_matrix_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90520ca2",
   "metadata": {},
   "source": [
    "### For Spam Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f7c2e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents_list_spam = email_train_spam['cleaned_contents'].tolist()\n",
    "\n",
    "#Create empty feature matrix\n",
    "feature_matrix_spam = np.zeros((len(contents_list_spam), len(dict_words)))\n",
    "\n",
    "#Loop over the emails\n",
    "for i, email in enumerate(contents_list_spam):\n",
    "    \n",
    "    #Check if the word in the dictionary appears in the email\n",
    "    for j, word in enumerate(dict_words):\n",
    "        if word in email:\n",
    "        \n",
    "            #If it appears, set the value to 1\n",
    "            feature_matrix_spam[i, j] = 1\n",
    "    else:\n",
    "        \n",
    "        #Set to 0\n",
    "        feature_matrix_spam[i, j] = 0\n",
    "\n",
    "feature_matrix_spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a20c91",
   "metadata": {},
   "source": [
    "# 3. Computing the Priors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20300e16",
   "metadata": {},
   "source": [
    "### Preparing Variabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85e77b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The number of ham emails in the training set\n",
    "train_size_ham = email_train_ham.shape[0]\n",
    "\n",
    "#The number of spam emails in the training set\n",
    "train_size_spam = email_train_spam.shape[0]\n",
    "\n",
    "#The total number of emails in train set\n",
    "total_email_size = email_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e75140f",
   "metadata": {},
   "source": [
    "### Solution for Prior Probabilities of Ham and Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83e0e6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(c = ham) = 0.3531924882629108\n",
      "P(c = spam) = 0.6468075117370892\n"
     ]
    }
   ],
   "source": [
    "#Solution for the prior probabilities for ham\n",
    "prior_ham =  train_size_ham / total_email_size\n",
    "\n",
    "#Solution for the prior probabilities for spam\n",
    "prior_spam = train_size_spam / total_email_size\n",
    "\n",
    "#Showing Results\n",
    "print(f\"P(c = ham) = {prior_ham}\")\n",
    "print(f\"P(c = spam) = {prior_spam}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c739977",
   "metadata": {},
   "source": [
    "# 4. Computing the Likelihood of each word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783cf6a1",
   "metadata": {},
   "source": [
    "### Preparing Variabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33dbcce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add all the spam words\n",
    "words_train_spam_sum = np.sum(feature_matrix_spam, axis=0)\n",
    "\n",
    "#Add all ham words\n",
    "words_train_ham_sum  = np.sum(feature_matrix_ham, axis=0)\n",
    "\n",
    "#Total sum of spam words\n",
    "words_train_spam_sum_total = words_train_spam_sum.sum()\n",
    "\n",
    "#Total sum of ham words\n",
    "words_train_ham_sum_total = words_train_ham_sum.sum()\n",
    "\n",
    "#For laplace smoothing\n",
    "laplace_smoothing = 1 \n",
    "\n",
    "#Create blank dicts\n",
    "likelihood_ham = {}\n",
    "likelihood_spam = {}\n",
    "#formula based on the given formula in the instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57daf3a5",
   "metadata": {},
   "source": [
    "### Solution for the Likelihood of Each Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "135bd687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result Sample\n",
      "\n",
      "Likelyhood of \"d\" occuring as spam is 0.002734251142013482.\n",
      "\n",
      "Likelyhood of \"d\" occuring as ham is 0.0026568330750450513.\n"
     ]
    }
   ],
   "source": [
    "uniq_words = dictionary['word'].tolist()\n",
    "\n",
    "for i in range(len(uniq_words)):\n",
    "\n",
    "    #Getting each word's occurance (spam)\n",
    "    occur_spam = (words_train_spam_sum[i] + laplace_smoothing) / (words_train_spam_sum_total + laplace_smoothing * len(uniq_words))\n",
    "    likelihood_spam[uniq_words[i]] = occur_spam  \n",
    "    \n",
    "    #Getting each word's occurance (ham)\n",
    "    occur_ham = (words_train_ham_sum[i] + laplace_smoothing) / (words_train_ham_sum_total + laplace_smoothing * len(uniq_words))\n",
    "    likelihood_ham[uniq_words[i]] = occur_ham\n",
    "\n",
    "#Sample\n",
    "#likelihood_spam\n",
    "first_key_spam, first_value_spam = next(iter(likelihood_spam.items()))\n",
    "print(f\"Result Sample\\n\\nLikelyhood of \\\"{first_key_spam}\\\" occuring as spam is {first_value_spam}.\")\n",
    "\n",
    "#likelihood_ham\n",
    "first_key_ham, first_value_ham = next(iter(likelihood_ham.items()))\n",
    "print(f\"\\nLikelyhood of \\\"{first_key_ham}\\\" occuring as ham is {first_value_ham}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2694d23",
   "metadata": {},
   "source": [
    "# 5. Classifying the emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "757bf7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functiom to classify if it's a spam or ham based on the probability of its word's occurrance\n",
    "contents_list = emails['cleaned_contents'].tolist()\n",
    "def email_classify(prior_spam, prior_ham, contents_list, likelihood_spam, likelihood_ham, uniq_words):\n",
    "    \n",
    "    #Converting the prior probabilities of spam and ham to log probabilities for numerical stability\n",
    "    log_prob_spam = np.log(prior_spam)\n",
    "    log_prob_ham = np.log(prior_ham)\n",
    "    \n",
    "    #Split the cleaned email contents into a list of individual words\n",
    "    body = str(contents_list).split()\n",
    "    \n",
    "    for word in body:\n",
    "\n",
    "        #Update the log probabilities if the word is in the list of unique words\n",
    "        if word in uniq_words:\n",
    "            log_prob_spam += np.log(likelihood_spam[word])            \n",
    "            log_prob_ham += np.log(likelihood_ham[word])\n",
    "\n",
    "    #Check if it is more likely to be spam or ham\n",
    "    if log_prob_spam > log_prob_ham:\n",
    "        return \"spam\"\n",
    "    else:\n",
    "        return \"ham\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2098788a",
   "metadata": {},
   "source": [
    "# 6. Testing the Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396c81b1",
   "metadata": {},
   "source": [
    "### Testing if the predicted label and actual label is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "086c8c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test it to all the emails\n",
    "predicted_label = []\n",
    "\n",
    "#Go through each email content and classify them\n",
    "for content in contents_list:\n",
    "    predicted = email_classify(prior_spam, prior_ham, content, likelihood_spam, likelihood_ham, uniq_words)\n",
    "    predicted_label.append(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2657e2",
   "metadata": {},
   "source": [
    "### Add to the DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "281cb816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>predicted label</th>\n",
       "      <th>path</th>\n",
       "      <th>contents</th>\n",
       "      <th>cleaned_contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>data/000/000</td>\n",
       "      <td>Received: from rodan.UU.NET by aramis.rutgers....</td>\n",
       "      <td>the mailing list i queried about a few weeks a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "      <td>data/000/001</td>\n",
       "      <td>Received: from unknown (HELO groucho.cs.psu.ed...</td>\n",
       "      <td>luxury watches   buy your own rolex for only  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "      <td>data/000/002</td>\n",
       "      <td>Received:\\n\\tfrom 24-151-178-89.dhcp.kgpt.tn.c...</td>\n",
       "      <td>academic qualifications available from prestig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>data/000/003</td>\n",
       "      <td>Received: from psuvax1.cs.psu.edu ([130.203.2....</td>\n",
       "      <td>greetings all  this is to verify your subscrip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "      <td>data/000/004</td>\n",
       "      <td>Received: from 201-1-198-159.dsl.telesp.net.br...</td>\n",
       "      <td>html   head   meta   equiv  content language ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "      <td>data/003/095</td>\n",
       "      <td>Received: from mail.oh-oku.com (61-30-232-94.s...</td>\n",
       "      <td>b                                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>data/003/096</td>\n",
       "      <td>Received: from unicorn.acs.ttu.edu (unicorn.ac...</td>\n",
       "      <td>wind erosion list members  the following annou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>data/003/097</td>\n",
       "      <td>Received: from unicorn.acs.ttu.edu (unicorn.ac...</td>\n",
       "      <td>we want to update some information on land dam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "      <td>data/003/098</td>\n",
       "      <td>Received: from mail.oh-oku.com (61-30-232-94.s...</td>\n",
       "      <td>b                                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>data/003/099</td>\n",
       "      <td>Received: from bottom.magnus.acs.ohio-state.ed...</td>\n",
       "      <td>rob schuette s early work   the  brown  period...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label predicted label          path  \\\n",
       "0     ham             ham  data/000/000   \n",
       "1    spam            spam  data/000/001   \n",
       "2    spam            spam  data/000/002   \n",
       "3     ham             ham  data/000/003   \n",
       "4    spam            spam  data/000/004   \n",
       "..    ...             ...           ...   \n",
       "995  spam            spam  data/003/095   \n",
       "996   ham             ham  data/003/096   \n",
       "997   ham             ham  data/003/097   \n",
       "998  spam            spam  data/003/098   \n",
       "999   ham             ham  data/003/099   \n",
       "\n",
       "                                              contents  \\\n",
       "0    Received: from rodan.UU.NET by aramis.rutgers....   \n",
       "1    Received: from unknown (HELO groucho.cs.psu.ed...   \n",
       "2    Received:\\n\\tfrom 24-151-178-89.dhcp.kgpt.tn.c...   \n",
       "3    Received: from psuvax1.cs.psu.edu ([130.203.2....   \n",
       "4    Received: from 201-1-198-159.dsl.telesp.net.br...   \n",
       "..                                                 ...   \n",
       "995  Received: from mail.oh-oku.com (61-30-232-94.s...   \n",
       "996  Received: from unicorn.acs.ttu.edu (unicorn.ac...   \n",
       "997  Received: from unicorn.acs.ttu.edu (unicorn.ac...   \n",
       "998  Received: from mail.oh-oku.com (61-30-232-94.s...   \n",
       "999  Received: from bottom.magnus.acs.ohio-state.ed...   \n",
       "\n",
       "                                      cleaned_contents  \n",
       "0    the mailing list i queried about a few weeks a...  \n",
       "1    luxury watches   buy your own rolex for only  ...  \n",
       "2    academic qualifications available from prestig...  \n",
       "3    greetings all  this is to verify your subscrip...  \n",
       "4     html   head   meta   equiv  content language ...  \n",
       "..                                                 ...  \n",
       "995    b                                           ...  \n",
       "996  wind erosion list members  the following annou...  \n",
       "997  we want to update some information on land dam...  \n",
       "998    b                                           ...  \n",
       "999  rob schuette s early work   the  brown  period...  \n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Insert to the right side of label to easily make a comparison\n",
    "emails.insert(1, 'predicted label', predicted_label)\n",
    "emails.head(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec912e86",
   "metadata": {},
   "source": [
    "### Count how many correct emails were classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a357ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly classified emails account to 35261/37822 or 93.23%\n"
     ]
    }
   ],
   "source": [
    "#Count rows that are equal\n",
    "count = (emails['label'].eq(emails['predicted label'])).sum()\n",
    "total = len(contents_list)\n",
    "\n",
    "#Convert to Percentage\n",
    "percentage = count/total * 100\n",
    "percentage = round(percentage, 2)\n",
    "\n",
    "print(f\"Correctly classified emails account to {count}/{total} or {percentage}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca938f3",
   "metadata": {},
   "source": [
    "# 7. Performance Evaluation Without Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4522d0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Evaluation:\n",
      "\n",
      "The Accuracy Score is 0.9322880862989794 or 93.23%\n",
      "The Recall Score is 0.9181254841208366 or 91.81%\n",
      "The Precision Score is 0.8873998652392004 or 88.74%\n"
     ]
    }
   ],
   "source": [
    "#Performance evaluation accuracy, recall, and precision\n",
    "label_actual = emails['label'].to_numpy()\n",
    "label_pred = emails['predicted label'].to_numpy()\n",
    "\n",
    "#For Accuracy\n",
    "#Round to 2 decimal places and convert to percentage\n",
    "accuracy_result = accuracy_score(label_actual, label_pred)\n",
    "accuracy_result_p = round(accuracy_result * 100, 2)\n",
    "\n",
    "#For Recall\n",
    "recall_result = recall_score(label_actual, label_pred, pos_label=\"ham\")\n",
    "recall_result_p = round(recall_result * 100, 2)\n",
    "\n",
    "#For Precision\n",
    "precision_result = precision_score(label_actual, label_pred, pos_label=\"ham\")\n",
    "precision_result_p = round(precision_result *100, 2)\n",
    "\n",
    "#Results\n",
    "print(\"Performance Evaluation:\\n\")\n",
    "print(f\"The Accuracy Score is {accuracy_result} or {accuracy_result_p}%\")\n",
    "print(f\"The Recall Score is {recall_result} or {recall_result_p}%\")\n",
    "print(f\"The Precision Score is {precision_result} or {precision_result_p}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d166bc",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1857a413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Confusion Matrix:\n",
      "\n",
      "[[11853  1057]\n",
      " [ 1504 23408]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "confusion_mat = confusion_matrix(label_actual,label_pred)\n",
    "print(\"The Confusion Matrix:\\n\")\n",
    "print(confusion_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2ba1bd",
   "metadata": {},
   "source": [
    "# ======================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a017a8c0",
   "metadata": {},
   "source": [
    "### Showing Table Evaluation Result with Stop Words and Without"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f495b572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>With Stop Words</th>\n",
       "      <th>No Stop Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>94.26%</td>\n",
       "      <td>93.23%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>91.12%</td>\n",
       "      <td>91.81%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>91.99%</td>\n",
       "      <td>88.74%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          With Stop Words No Stop Words\n",
       "Accuracy           94.26%        93.23%\n",
       "Recall             91.12%        91.81%\n",
       "Precision          91.99%        88.74%"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To create a table, we create a dictionary with the data for the DataFrame\n",
    "acc = str(accuracy_result_p) + \"%\"\n",
    "rec = str(recall_result_p) + \"%\"\n",
    "prec = str(precision_result_p) + \"%\"\n",
    "\n",
    "data = {\n",
    "    \"With Stop Words\": [\"94.26%\", \"91.12%\", \"91.99%\"],\n",
    "    \"No Stop Words\": [acc, rec, prec]\n",
    "}\n",
    "table = pd.DataFrame(data, index=[\"Accuracy\", \"Recall\", \"Precision\"])\n",
    "\n",
    "table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a53d5e2",
   "metadata": {},
   "source": [
    "The Table shows no difference whether we add the stop words or not in our results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4807895",
   "metadata": {},
   "source": [
    "# ======================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317da294",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
